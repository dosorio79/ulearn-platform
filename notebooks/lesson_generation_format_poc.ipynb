{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970bfda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env file\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a888d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target internal schemas\n",
    "\n",
    "BlockType = Literal[\"text\", \"python\"]\n",
    "SectionID = Literal[\"concept\", \"example\", \"exercise\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BlockDraft:\n",
    "    type: BlockType\n",
    "    content: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SectionDraft:\n",
    "    id: SectionID\n",
    "    title: str\n",
    "    minutes: int\n",
    "    blocks: List[BlockDraft]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LessonDraft:\n",
    "    objective: str\n",
    "    sections: List[SectionDraft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9d090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"objective\": \"Describe the learner outcome in one sentence.\",\n",
      "  \"sections\": [\n",
      "    {\n",
      "      \"id\": \"concept\",\n",
      "      \"title\": \"Key idea or principle\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Explain the concept in plain language.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"example\",\n",
      "      \"title\": \"Worked example\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Walk through the example step by step.\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"python\",\n",
      "          \"content\": \"print('Example code here')\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"exercise\",\n",
      "      \"title\": \"Practice task\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Provide an exercise prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Human readable schema for prompt mathcing previous cell data classes\n",
    "\n",
    "EXPECTED_SCHEMA = \"\"\"\n",
    "{\n",
    "  \"objective\": \"Describe the learner outcome in one sentence.\",\n",
    "  \"sections\": [\n",
    "    {\n",
    "      \"id\": \"concept\",\n",
    "      \"title\": \"Key idea or principle\",\n",
    "      \"minutes\": 5,\n",
    "      \"blocks\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"content\": \"Explain the concept in plain language.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"example\",\n",
    "      \"title\": \"Worked example\",\n",
    "      \"minutes\": 5,\n",
    "      \"blocks\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"content\": \"Walk through the example step by step.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"python\",\n",
    "          \"content\": \"print('Example code here')\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"exercise\",\n",
    "      \"title\": \"Practice task\",\n",
    "      \"minutes\": 5,\n",
    "      \"blocks\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"content\": \"Provide an exercise prompt.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "print(EXPECTED_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb29fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert instructor. Create a concise 15-minute lesson on \"pandas groupby performance\" for a \"beginner\" learner.\n",
      "\n",
      "Return VALID JSON ONLY that matches this schema (no extra keys):\n",
      "\n",
      "{\n",
      "  \"objective\": \"Describe the learner outcome in one sentence.\",\n",
      "  \"sections\": [\n",
      "    {\n",
      "      \"id\": \"concept\",\n",
      "      \"title\": \"Key idea or principle\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Explain the concept in plain language.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"example\",\n",
      "      \"title\": \"Worked example\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Walk through the example step by step.\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"python\",\n",
      "          \"content\": \"print('Example code here')\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"exercise\",\n",
      "      \"title\": \"Practice task\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Provide an exercise prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "Hard requirements:\n",
      "- Total minutes across sections must sum to exactly 15.\n",
      "- Use 1-3 sections total.\n",
      "- section.id must be one of: \"concept\", \"example\", \"exercise\".\n",
      "- Each section must include at least 1 block.\n",
      "- block.type must be \"text\" or \"python\".\n",
      "- At least one block.type must be \"python\".\n",
      "- Python blocks must be runnable, minimal, and directly related to the topic.\n",
      "\n",
      "Quality guidelines:\n",
      "- Objective is one sentence, specific and measurable.\n",
      "- concept: teach the key idea(s) in plain language.\n",
      "- example: walk through a small, concrete example with code and short explanations.\n",
      "- exercise: give a short practice task; no solutions.\n",
      "\n",
      "Formatting rules:\n",
      "- Output JSON only, no markdown fences, no commentary.\n",
      "- Use double quotes for all keys/strings.\n",
      "\n",
      "Now produce the JSON.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert instructor. Create a concise 15-minute lesson on \"{topic}\" for a \"{level}\" learner.\n",
    "\n",
    "Return VALID JSON ONLY that matches this schema (no extra keys):\n",
    "{schema}\n",
    "\n",
    "Hard requirements:\n",
    "- Total minutes across sections must sum to exactly 15.\n",
    "- Use 1-3 sections total.\n",
    "- section.id must be one of: \"concept\", \"example\", \"exercise\".\n",
    "- Each section must include at least 1 block.\n",
    "- block.type must be \"text\" or \"python\".\n",
    "- At least one block.type must be \"python\".\n",
    "- Python blocks must be runnable, minimal, and directly related to the topic.\n",
    "\n",
    "Quality guidelines:\n",
    "- Objective is one sentence, specific and measurable.\n",
    "- concept: teach the key idea(s) in plain language.\n",
    "- example: walk through a small, concrete example with code and short explanations.\n",
    "- exercise: give a short practice task; no solutions.\n",
    "\n",
    "Formatting rules:\n",
    "- Output JSON only, no markdown fences, no commentary.\n",
    "- Use double quotes for all keys/strings.\n",
    "\n",
    "Now produce the JSON.\n",
    "\"\"\"\n",
    "\n",
    "print(PROMPT_TEMPLATE.format(\n",
    "    topic=\"pandas groupby performance\",\n",
    "    level=\"beginner\",\n",
    "    schema=EXPECTED_SCHEMA\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4aae417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"objective\": \"Understand how to use pandas groupby efficiently and recognize factors affecting its performance.\",\n",
      "  \"sections\": [\n",
      "    {\n",
      "      \"id\": \"concept\",\n",
      "      \"title\": \"Understanding pandas groupby and its performance factors\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"The pandas groupby function splits data into groups based on column values and applies aggregation or transformation operations. While groupby is powerful, performance depends on factors like data size, number of groups, and the complexity of the aggregation function. Using built-in aggregation methods and minimizing custom functions improves speed.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"example\",\n",
      "      \"title\": \"Grouping and aggregating data with pandas\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"We will group a small DataFrame by a column and calculate the sum of another column. This uses a built-in aggregation function, which is efficient.\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"python\",\n",
      "          \"content\": \"import pandas as pd\\n\\ndata = {'Category': ['A', 'B', 'A', 'B', 'C'],\\n        'Values': [10, 20, 30, 40, 50]}\\ndf = pd.DataFrame(data)\\n\\ngrouped = df.groupby('Category')['Values'].sum()\\nprint(grouped)\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"exercise\",\n",
      "      \"title\": \"Practice grouping and measuring performance\",\n",
      "      \"minutes\": 5,\n",
      "      \"blocks\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"Create a DataFrame with 1000 rows and two columns: 'Group' with random letters from A to D, and 'Data' with random numbers. Use groupby to calculate the mean of 'Data' for each group. Try timing the operation using %timeit in Jupyter or time module in Python to observe performance.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Make a call to openAI with the above prompt \n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that creates lesson plans in JSON format.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT_TEMPLATE.format(\n",
    "                topic=\"pandas groupby performance\",\n",
    "                level=\"beginner\",\n",
    "                schema=EXPECTED_SCHEMA\n",
    "            )\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1500,\n",
    ")\n",
    "lesson_json = response.choices[0].message.content\n",
    "print(lesson_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae476cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'Understand how to use pandas groupby efficiently and recognize factors affecting its performance.',\n",
       " 'sections': [{'id': 'concept',\n",
       "   'title': 'Understanding pandas groupby and its performance factors',\n",
       "   'minutes': 5,\n",
       "   'blocks': [{'type': 'text',\n",
       "     'content': 'The pandas groupby function splits data into groups based on column values and applies aggregation or transformation operations. While groupby is powerful, performance depends on factors like data size, number of groups, and the complexity of the aggregation function. Using built-in aggregation methods and minimizing custom functions improves speed.'}]},\n",
       "  {'id': 'example',\n",
       "   'title': 'Grouping and aggregating data with pandas',\n",
       "   'minutes': 5,\n",
       "   'blocks': [{'type': 'text',\n",
       "     'content': 'We will group a small DataFrame by a column and calculate the sum of another column. This uses a built-in aggregation function, which is efficient.'},\n",
       "    {'type': 'python',\n",
       "     'content': \"import pandas as pd\\n\\ndata = {'Category': ['A', 'B', 'A', 'B', 'C'],\\n        'Values': [10, 20, 30, 40, 50]}\\ndf = pd.DataFrame(data)\\n\\ngrouped = df.groupby('Category')['Values'].sum()\\nprint(grouped)\"}]},\n",
       "  {'id': 'exercise',\n",
       "   'title': 'Practice grouping and measuring performance',\n",
       "   'minutes': 5,\n",
       "   'blocks': [{'type': 'text',\n",
       "     'content': \"Create a DataFrame with 1000 rows and two columns: 'Group' with random letters from A to D, and 'Data' with random numbers. Use groupby to calculate the mean of 'Data' for each group. Try timing the operation using %timeit in Jupyter or time module in Python to observe performance.\"}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(lesson_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99102122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch testing with different topics and levels\n",
    "TEST_CASES = {\n",
    "    \"programming_beginner\": {\n",
    "        \"topic\": \"pandas groupby performance\",\n",
    "        \"level\": \"beginner\",\n",
    "    },\n",
    "    \"programming_intermediate\": {\n",
    "        \"topic\": \"optimize pandas groupby memory usage\",\n",
    "        \"level\": \"intermediate\",\n",
    "    },\n",
    "    \"data_concept_beginner\": {\n",
    "        \"topic\": \"correlation vs causation\",\n",
    "        \"level\": \"beginner\",\n",
    "    },\n",
    "    \"data_concept_intermediate\": {\n",
    "        \"topic\": \"bias vs variance trade-off\",\n",
    "        \"level\": \"intermediate\",\n",
    "    },\n",
    "    \"analytics_reasoning_beginner\": {\n",
    "        \"topic\": \"interpreting A/B test results\",\n",
    "        \"level\": \"beginner\",\n",
    "    },\n",
    "    \"analytics_reasoning_intermediate\": {\n",
    "        \"topic\": \"common pitfalls in KPI interpretation\",\n",
    "        \"level\": \"intermediate\",\n",
    "    },\n",
    "    \"statistics_intuition_beginner\": {\n",
    "        \"topic\": \"what a p-value means\",\n",
    "        \"level\": \"beginner\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cb7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lesson(topic: str, level: str, temperature: float = 0.7, max_tokens: int = 1500) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a lesson plan using OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "        topic: The lesson topic\n",
    "        level: The learner level (e.g., \"beginner\", \"intermediate\")\n",
    "        temperature: OpenAI temperature parameter (default: 0.7)\n",
    "        max_tokens: Maximum tokens in response (default: 1500)\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys: topic, level, valid_json, lesson_data, raw_output\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that creates lesson plans in JSON format.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": PROMPT_TEMPLATE.format(\n",
    "                    topic=topic,\n",
    "                    level=level,\n",
    "                    schema=EXPECTED_SCHEMA\n",
    "                )\n",
    "            }\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d994de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating lesson for case: programming_beginner\n",
      "Generating lesson for case: programming_intermediate\n",
      "Generating lesson for case: data_concept_beginner\n",
      "Generating lesson for case: data_concept_intermediate\n",
      "Generating lesson for case: analytics_reasoning_beginner\n",
      "Generating lesson for case: analytics_reasoning_intermediate\n",
      "Generating lesson for case: statistics_intuition_beginner\n"
     ]
    }
   ],
   "source": [
    "# Run tests and collect results in a dataframe\n",
    "results = []\n",
    "for case_name, case_params in TEST_CASES.items():\n",
    "    print(f\"Generating lesson for case: {case_name}\")\n",
    "    raw_output = generate_lesson(\n",
    "        topic=case_params[\"topic\"],\n",
    "        level=case_params[\"level\"]\n",
    "    )\n",
    "    try:\n",
    "        lesson_data = json.loads(raw_output)\n",
    "        valid_json = True\n",
    "    except json.JSONDecodeError:\n",
    "        lesson_data = None\n",
    "        valid_json = False\n",
    "\n",
    "    results.append({\n",
    "        \"case\": case_name,\n",
    "        \"topic\": case_params[\"topic\"],\n",
    "        \"level\": case_params[\"level\"],\n",
    "        \"valid_json\": valid_json,\n",
    "        \"lesson_data\": lesson_data,\n",
    "        \"raw_output\": raw_output,\n",
    "    })\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01f2eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "case",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "valid_json",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "lesson_data",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw_output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b255cfbc-9cfa-4fc2-99eb-ebd9cd4d9a3d",
       "rows": [
        [
         "0",
         "programming_beginner",
         "pandas groupby performance",
         "beginner",
         "True",
         "{'objective': 'Understand how to use pandas groupby efficiently and recognize factors that affect its performance.', 'sections': [{'id': 'concept', 'title': 'Key idea or principle', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'The pandas groupby function is used to split data into groups based on some criteria and apply functions to each group. Performance depends on the size of the data, the number of groups, and the complexity of the operation applied. Using efficient aggregation functions and minimizing the number of groups can improve speed. Also, avoiding complex custom functions and using built-in pandas methods helps performance.'}]}, {'id': 'example', 'title': 'Worked example', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'We will create a small DataFrame and use groupby to calculate the mean of a column by group. We will use built-in aggregation which is efficient and show how it works.'}, {'type': 'python', 'content': \"import pandas as pd\\n\\ndata = {'category': ['A', 'B', 'A', 'B', 'C', 'A', 'C'],\\n        'value': [10, 20, 15, 10, 30, 45, 25]}\\ndf = pd.DataFrame(data)\\n\\n# Group by 'category' and calculate mean of 'value'\\ngrouped = df.groupby('category')['value'].mean()\\nprint(grouped)\"}]}, {'id': 'exercise', 'title': 'Practice task', 'minutes': 5, 'blocks': [{'type': 'text', 'content': \"Create a DataFrame with columns 'team' and 'score' containing at least 10 rows. Use groupby to find the maximum score for each team. Try to use a built-in aggregation function for best performance.\"}]}]}",
         "{\n  \"objective\": \"Understand how to use pandas groupby efficiently and recognize factors that affect its performance.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Key idea or principle\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"The pandas groupby function is used to split data into groups based on some criteria and apply functions to each group. Performance depends on the size of the data, the number of groups, and the complexity of the operation applied. Using efficient aggregation functions and minimizing the number of groups can improve speed. Also, avoiding complex custom functions and using built-in pandas methods helps performance.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Worked example\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"We will create a small DataFrame and use groupby to calculate the mean of a column by group. We will use built-in aggregation which is efficient and show how it works.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"import pandas as pd\\n\\ndata = {'category': ['A', 'B', 'A', 'B', 'C', 'A', 'C'],\\n        'value': [10, 20, 15, 10, 30, 45, 25]}\\ndf = pd.DataFrame(data)\\n\\n# Group by 'category' and calculate mean of 'value'\\ngrouped = df.groupby('category')['value'].mean()\\nprint(grouped)\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Practice task\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Create a DataFrame with columns 'team' and 'score' containing at least 10 rows. Use groupby to find the maximum score for each team. Try to use a built-in aggregation function for best performance.\"\n        }\n      ]\n    }\n  ]\n}"
        ],
        [
         "1",
         "programming_intermediate",
         "optimize pandas groupby memory usage",
         "intermediate",
         "True",
         "{'objective': 'Learn to reduce memory usage when performing groupby operations in pandas by optimizing data types and processing strategies.', 'sections': [{'id': 'concept', 'title': 'Understanding Memory Usage in pandas GroupBy', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'When using pandas groupby, memory usage can increase significantly due to the creation of intermediate objects and the nature of data types. Optimizing memory involves converting columns to more efficient types (e.g., categoricals for strings, smaller integer types) before grouping, and minimizing the size of the resulting objects.'}]}, {'id': 'example', 'title': 'Optimizing Memory Usage: A Step-by-Step Example', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'We will demonstrate how converting a string column to categorical type before grouping reduces memory usage and speeds up the groupby aggregation.'}, {'type': 'python', 'content': \"import pandas as pd\\nimport numpy as np\\n\\n# Create a sample DataFrame with a string column\\nnp.random.seed(0)\\nsize = 100000\\ncategories = ['A', 'B', 'C', 'D']\\ndf = pd.DataFrame({\\n    'Category': np.random.choice(categories, size=size),\\n    'Value': np.random.rand(size)\\n})\\n\\n# Check memory usage before optimization\\nmem_before = df.memory_usage(deep=True).sum()\\n\\n# Convert 'Category' to categorical type\\ndf['Category'] = df['Category'].astype('category')\\n\\n# Check memory usage after optimization\\nmem_after = df.memory_usage(deep=True).sum()\\n\\n# Perform groupby aggregation\\nresult = df.groupby('Category')['Value'].mean()\\n\\nmem_before, mem_after, result\"}]}, {'id': 'exercise', 'title': 'Practice Task: Optimize GroupBy Memory Usage', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Given a DataFrame with integer and string columns, convert appropriate columns to more memory-efficient types before performing a groupby aggregation to minimize memory usage. Measure memory before and after optimization.'}]}]}",
         "{\n  \"objective\": \"Learn to reduce memory usage when performing groupby operations in pandas by optimizing data types and processing strategies.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Understanding Memory Usage in pandas GroupBy\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"When using pandas groupby, memory usage can increase significantly due to the creation of intermediate objects and the nature of data types. Optimizing memory involves converting columns to more efficient types (e.g., categoricals for strings, smaller integer types) before grouping, and minimizing the size of the resulting objects.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Optimizing Memory Usage: A Step-by-Step Example\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"We will demonstrate how converting a string column to categorical type before grouping reduces memory usage and speeds up the groupby aggregation.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"import pandas as pd\\nimport numpy as np\\n\\n# Create a sample DataFrame with a string column\\nnp.random.seed(0)\\nsize = 100000\\ncategories = ['A', 'B', 'C', 'D']\\ndf = pd.DataFrame({\\n    'Category': np.random.choice(categories, size=size),\\n    'Value': np.random.rand(size)\\n})\\n\\n# Check memory usage before optimization\\nmem_before = df.memory_usage(deep=True).sum()\\n\\n# Convert 'Category' to categorical type\\ndf['Category'] = df['Category'].astype('category')\\n\\n# Check memory usage after optimization\\nmem_after = df.memory_usage(deep=True).sum()\\n\\n# Perform groupby aggregation\\nresult = df.groupby('Category')['Value'].mean()\\n\\nmem_before, mem_after, result\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Practice Task: Optimize GroupBy Memory Usage\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Given a DataFrame with integer and string columns, convert appropriate columns to more memory-efficient types before performing a groupby aggregation to minimize memory usage. Measure memory before and after optimization.\"\n        }\n      ]\n    }\n  ]\n}"
        ],
        [
         "2",
         "data_concept_beginner",
         "correlation vs causation",
         "beginner",
         "True",
         "{'objective': 'Explain the difference between correlation and causation and identify examples of each.', 'sections': [{'id': 'concept', 'title': 'Key idea or principle', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Correlation means two things happen or change together, but it doesn’t mean one causes the other. Causation means one thing actually causes the other to happen.'}, {'type': 'text', 'content': \"Just because two things are related (correlated), it doesn't mean one causes the other. For example, ice cream sales and drowning incidents both increase in summer, but ice cream does not cause drowning.\"}]}, {'id': 'example', 'title': 'Worked example', 'minutes': 5, 'blocks': [{'type': 'text', 'content': \"Let's look at a simple example with some data. We will check if two variables are correlated and discuss whether one causes the other.\"}, {'type': 'python', 'content': \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Example data: hours studied and test scores\\nhours_studied = np.array([1, 2, 3, 4, 5, 6])\\ntest_scores = np.array([50, 55, 65, 70, 75, 80])\\n\\n# Calculate correlation coefficient\\ncorrelation = np.corrcoef(hours_studied, test_scores)[0,1]\\n\\nplt.scatter(hours_studied, test_scores)\\nplt.xlabel('Hours Studied')\\nplt.ylabel('Test Scores')\\nplt.title(f'Correlation: {correlation:.2f}')\\nplt.show()\\n\\nprint(f'Correlation coefficient: {correlation:.2f}')\"}]}, {'id': 'exercise', 'title': 'Practice task', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Find two variables you think might be correlated in your daily life. Describe if you think one causes the other or if they just happen together. Explain why.'}]}]}",
         "{\n  \"objective\": \"Explain the difference between correlation and causation and identify examples of each.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Key idea or principle\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Correlation means two things happen or change together, but it doesn’t mean one causes the other. Causation means one thing actually causes the other to happen.\"\n        },\n        {\n          \"type\": \"text\",\n          \"content\": \"Just because two things are related (correlated), it doesn't mean one causes the other. For example, ice cream sales and drowning incidents both increase in summer, but ice cream does not cause drowning.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Worked example\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Let's look at a simple example with some data. We will check if two variables are correlated and discuss whether one causes the other.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"import numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Example data: hours studied and test scores\\nhours_studied = np.array([1, 2, 3, 4, 5, 6])\\ntest_scores = np.array([50, 55, 65, 70, 75, 80])\\n\\n# Calculate correlation coefficient\\ncorrelation = np.corrcoef(hours_studied, test_scores)[0,1]\\n\\nplt.scatter(hours_studied, test_scores)\\nplt.xlabel('Hours Studied')\\nplt.ylabel('Test Scores')\\nplt.title(f'Correlation: {correlation:.2f}')\\nplt.show()\\n\\nprint(f'Correlation coefficient: {correlation:.2f}')\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Practice task\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Find two variables you think might be correlated in your daily life. Describe if you think one causes the other or if they just happen together. Explain why.\"\n        }\n      ]\n    }\n  ]\n}"
        ],
        [
         "3",
         "data_concept_intermediate",
         "bias vs variance trade-off",
         "intermediate",
         "True",
         "{'objective': 'Explain the bias-variance trade-off in machine learning and demonstrate its effect on model performance through a simple example.', 'sections': [{'id': 'concept', 'title': 'Bias-Variance Trade-Off: Key idea', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'The bias-variance trade-off is a fundamental concept in machine learning that describes the balance between two types of errors that affect model performance. Bias refers to errors due to overly simplistic assumptions in the model, leading to underfitting. Variance refers to errors from too much sensitivity to small fluctuations in the training data, causing overfitting. A good model finds a balance, minimizing total error by managing both bias and variance.'}]}, {'id': 'example', 'title': 'Worked Example', 'minutes': 5, 'blocks': [{'type': 'text', 'content': \"Let's illustrate bias and variance using polynomial regression on a noisy dataset. Low-degree polynomials have high bias and low variance (underfitting), while high-degree polynomials have low bias and high variance (overfitting). We'll fit polynomials of degree 1, 3, and 9 and observe training and testing errors.\"}, {'type': 'python', 'content': \"import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.preprocessing import PolynomialFeatures\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.model_selection import train_test_split\\n\\n# Generate data\\nnp.random.seed(0)\\nx = np.linspace(0, 1, 30)\\ny = np.sin(2 * np.pi * x) + np.random.normal(scale=0.3, size=x.shape)\\n\\n# Split data\\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\\n\\n# Prepare plot\\nplt.figure(figsize=(10,6))\\nplt.scatter(x_train, y_train, label='Train data')\\nplt.scatter(x_test, y_test, label='Test data')\\nx_plot = np.linspace(0, 1, 100).reshape(-1,1)\\n\\nfor degree in [1,3,9]:\\n    poly = PolynomialFeatures(degree)\\n    X_train_poly = poly.fit_transform(x_train.reshape(-1,1))\\n    X_test_poly = poly.transform(x_test.reshape(-1,1))\\n    model = LinearRegression().fit(X_train_poly, y_train)\\n    y_train_pred = model.predict(X_train_poly)\\n    y_test_pred = model.predict(X_test_poly)\\n    train_err = mean_squared_error(y_train, y_train_pred)\\n    test_err = mean_squared_error(y_test, y_test_pred)\\n    \\n    # Plot prediction\\n    X_plot_poly = poly.transform(x_plot)\\n    y_plot = model.predict(X_plot_poly)\\n    plt.plot(x_plot, y_plot, label=f'Degree {degree} (Train MSE: {train_err:.2f}, Test MSE: {test_err:.2f})')\\n\\nplt.legend()\\nplt.title('Bias-Variance Trade-Off Example')\\nplt.show()\"}]}, {'id': 'exercise', 'title': 'Practice Task', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Using the example code, try fitting polynomial models of degrees 2, 5, and 7. Observe and explain how training and testing errors change with degree. Discuss which degree provides the best balance between bias and variance for this dataset.'}]}]}",
         "{\n  \"objective\": \"Explain the bias-variance trade-off in machine learning and demonstrate its effect on model performance through a simple example.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Bias-Variance Trade-Off: Key idea\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"The bias-variance trade-off is a fundamental concept in machine learning that describes the balance between two types of errors that affect model performance. Bias refers to errors due to overly simplistic assumptions in the model, leading to underfitting. Variance refers to errors from too much sensitivity to small fluctuations in the training data, causing overfitting. A good model finds a balance, minimizing total error by managing both bias and variance.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Worked Example\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Let's illustrate bias and variance using polynomial regression on a noisy dataset. Low-degree polynomials have high bias and low variance (underfitting), while high-degree polynomials have low bias and high variance (overfitting). We'll fit polynomials of degree 1, 3, and 9 and observe training and testing errors.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"import numpy as np\\nimport matplotlib.pyplot as plt\\nfrom sklearn.preprocessing import PolynomialFeatures\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.model_selection import train_test_split\\n\\n# Generate data\\nnp.random.seed(0)\\nx = np.linspace(0, 1, 30)\\ny = np.sin(2 * np.pi * x) + np.random.normal(scale=0.3, size=x.shape)\\n\\n# Split data\\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\\n\\n# Prepare plot\\nplt.figure(figsize=(10,6))\\nplt.scatter(x_train, y_train, label='Train data')\\nplt.scatter(x_test, y_test, label='Test data')\\nx_plot = np.linspace(0, 1, 100).reshape(-1,1)\\n\\nfor degree in [1,3,9]:\\n    poly = PolynomialFeatures(degree)\\n    X_train_poly = poly.fit_transform(x_train.reshape(-1,1))\\n    X_test_poly = poly.transform(x_test.reshape(-1,1))\\n    model = LinearRegression().fit(X_train_poly, y_train)\\n    y_train_pred = model.predict(X_train_poly)\\n    y_test_pred = model.predict(X_test_poly)\\n    train_err = mean_squared_error(y_train, y_train_pred)\\n    test_err = mean_squared_error(y_test, y_test_pred)\\n    \\n    # Plot prediction\\n    X_plot_poly = poly.transform(x_plot)\\n    y_plot = model.predict(X_plot_poly)\\n    plt.plot(x_plot, y_plot, label=f'Degree {degree} (Train MSE: {train_err:.2f}, Test MSE: {test_err:.2f})')\\n\\nplt.legend()\\nplt.title('Bias-Variance Trade-Off Example')\\nplt.show()\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Practice Task\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Using the example code, try fitting polynomial models of degrees 2, 5, and 7. Observe and explain how training and testing errors change with degree. Discuss which degree provides the best balance between bias and variance for this dataset.\"\n        }\n      ]\n    }\n  ]\n}"
        ],
        [
         "4",
         "analytics_reasoning_beginner",
         "interpreting A/B test results",
         "beginner",
         "True",
         "{'objective': 'Explain how to interpret the results of an A/B test including understanding conversion rates and statistical significance.', 'sections': [{'id': 'concept', 'title': 'Understanding A/B Test Results', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'An A/B test compares two versions (A and B) to see which performs better. We look at metrics like conversion rates to measure success. Interpretation involves comparing these rates and determining if differences are statistically significant, meaning they are unlikely due to chance.'}]}, {'id': 'example', 'title': 'Worked Example: Interpreting Conversion Rates', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Suppose version A has 1000 visitors with 100 conversions (10%) and version B has 1000 visitors with 120 conversions (12%). We want to check if the 2% difference is meaningful.'}, {'type': 'python', 'content': 'from statsmodels.stats.proportion import proportions_ztest\\n\\n# conversions and visitors\\nconv_A, n_A = 100, 1000\\nconv_B, n_B = 120, 1000\\n\\n# perform z-test\\ncount = [conv_A, conv_B]\\nnobs = [n_A, n_B]\\nstat, pval = proportions_ztest(count, nobs)\\n\\nprint(f\"Z-statistic: {stat:.2f}\")\\nprint(f\"P-value: {pval:.3f}\")\\n\\nif pval < 0.05:\\n    print(\"Result is statistically significant: B is likely better.\")\\nelse:\\n    print(\"No significant difference between A and B.\")'}]}, {'id': 'exercise', 'title': 'Practice Task: Analyze A/B Test Data', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Given version A with 150 conversions out of 1500 visitors and version B with 180 conversions out of 1600 visitors, calculate if the difference is statistically significant and interpret the result.'}]}]}",
         "{\n  \"objective\": \"Explain how to interpret the results of an A/B test including understanding conversion rates and statistical significance.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Understanding A/B Test Results\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"An A/B test compares two versions (A and B) to see which performs better. We look at metrics like conversion rates to measure success. Interpretation involves comparing these rates and determining if differences are statistically significant, meaning they are unlikely due to chance.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Worked Example: Interpreting Conversion Rates\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Suppose version A has 1000 visitors with 100 conversions (10%) and version B has 1000 visitors with 120 conversions (12%). We want to check if the 2% difference is meaningful.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"from statsmodels.stats.proportion import proportions_ztest\\n\\n# conversions and visitors\\nconv_A, n_A = 100, 1000\\nconv_B, n_B = 120, 1000\\n\\n# perform z-test\\ncount = [conv_A, conv_B]\\nnobs = [n_A, n_B]\\nstat, pval = proportions_ztest(count, nobs)\\n\\nprint(f\\\"Z-statistic: {stat:.2f}\\\")\\nprint(f\\\"P-value: {pval:.3f}\\\")\\n\\nif pval < 0.05:\\n    print(\\\"Result is statistically significant: B is likely better.\\\")\\nelse:\\n    print(\\\"No significant difference between A and B.\\\")\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Practice Task: Analyze A/B Test Data\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Given version A with 150 conversions out of 1500 visitors and version B with 180 conversions out of 1600 visitors, calculate if the difference is statistically significant and interpret the result.\"\n        }\n      ]\n    }\n  ]\n}"
        ],
        [
         "5",
         "analytics_reasoning_intermediate",
         "common pitfalls in KPI interpretation",
         "intermediate",
         "True",
         "{'objective': 'Identify and avoid common pitfalls when interpreting KPIs to make more accurate business decisions.', 'sections': [{'id': 'concept', 'title': 'Common Pitfalls in KPI Interpretation', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'KPIs (Key Performance Indicators) are essential metrics to measure success, but misinterpreting them can lead to wrong conclusions. Common pitfalls include ignoring context, focusing on a single KPI without considering others, misunderstanding causation vs correlation, overlooking data quality issues, and failing to consider time lags or external factors affecting the KPI.'}]}, {'id': 'example', 'title': 'Worked Example: Interpreting Conversion Rate', 'minutes': 5, 'blocks': [{'type': 'text', 'content': \"Consider an e-commerce site where the conversion rate dropped from 5% to 3%. At first glance, this looks negative. However, if the number of visitors doubled, the absolute number of conversions may have increased. Also, a change in marketing channels or seasonality may affect these numbers. Let's analyze this with code.\"}, {'type': 'python', 'content': 'visitors_before = 1000\\nconversions_before = 50  # 5%\\nvisitors_after = 2000\\nconversions_after = 60   # 3%\\n\\nconversion_rate_before = conversions_before / visitors_before\\nconversion_rate_after = conversions_after / visitors_after\\n\\nprint(f\"Before: {conversions_before} conversions out of {visitors_before} visitors ({conversion_rate_before:.1%})\")\\nprint(f\"After: {conversions_after} conversions out of {visitors_after} visitors ({conversion_rate_after:.1%})\")\\n\\nchange_in_conversion_rate = conversion_rate_after - conversion_rate_before\\nchange_in_conversions = conversions_after - conversions_before\\n\\nprint(f\"Change in conversion rate: {change_in_conversion_rate:.1%}\")\\nprint(f\"Change in total conversions: {change_in_conversions}\")'}]}, {'id': 'exercise', 'title': 'Practice Task: Analyze KPI Changes', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'You have two datasets with monthly sales revenue and number of customers for two different periods. Calculate the average sales per customer for each period and interpret whether the business performance improved or declined. Consider potential pitfalls when interpreting these KPIs.'}]}]}",
         "{\n  \"objective\": \"Identify and avoid common pitfalls when interpreting KPIs to make more accurate business decisions.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Common Pitfalls in KPI Interpretation\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"KPIs (Key Performance Indicators) are essential metrics to measure success, but misinterpreting them can lead to wrong conclusions. Common pitfalls include ignoring context, focusing on a single KPI without considering others, misunderstanding causation vs correlation, overlooking data quality issues, and failing to consider time lags or external factors affecting the KPI.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Worked Example: Interpreting Conversion Rate\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Consider an e-commerce site where the conversion rate dropped from 5% to 3%. At first glance, this looks negative. However, if the number of visitors doubled, the absolute number of conversions may have increased. Also, a change in marketing channels or seasonality may affect these numbers. Let's analyze this with code.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"visitors_before = 1000\\nconversions_before = 50  # 5%\\nvisitors_after = 2000\\nconversions_after = 60   # 3%\\n\\nconversion_rate_before = conversions_before / visitors_before\\nconversion_rate_after = conversions_after / visitors_after\\n\\nprint(f\\\"Before: {conversions_before} conversions out of {visitors_before} visitors ({conversion_rate_before:.1%})\\\")\\nprint(f\\\"After: {conversions_after} conversions out of {visitors_after} visitors ({conversion_rate_after:.1%})\\\")\\n\\nchange_in_conversion_rate = conversion_rate_after - conversion_rate_before\\nchange_in_conversions = conversions_after - conversions_before\\n\\nprint(f\\\"Change in conversion rate: {change_in_conversion_rate:.1%}\\\")\\nprint(f\\\"Change in total conversions: {change_in_conversions}\\\")\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Practice Task: Analyze KPI Changes\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"You have two datasets with monthly sales revenue and number of customers for two different periods. Calculate the average sales per customer for each period and interpret whether the business performance improved or declined. Consider potential pitfalls when interpreting these KPIs.\"\n        }\n      ]\n    }\n  ]\n}"
        ],
        [
         "6",
         "statistics_intuition_beginner",
         "what a p-value means",
         "beginner",
         "True",
         "{'objective': 'Explain what a p-value represents in hypothesis testing and interpret its meaning in context.', 'sections': [{'id': 'concept', 'title': 'Understanding the p-value', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'A p-value helps us decide if our data is surprising under a specific assumption called the null hypothesis. It tells us the probability of seeing data as extreme as ours if the null hypothesis is true. A small p-value means the observed data is unlikely under the null hypothesis, suggesting that we might question this assumption.'}]}, {'id': 'example', 'title': 'Worked example with coin flips', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Imagine you flip a coin 10 times to test if it is fair. You get 9 heads. The p-value tells us how likely it is to get 9 or more heads if the coin is fair (null hypothesis). We calculate this probability to see if getting 9 heads is surprising.'}, {'type': 'python', 'content': 'from scipy.stats import binom\\n\\n# Number of flips\\nn = 10\\n# Number of observed heads\\nk = 9\\n# Probability of heads under null hypothesis\\np = 0.5\\n\\n# Calculate p-value: probability of 9 or more heads if coin is fair\\np_value = binom.sf(k-1, n, p)  # sf(k-1) = P(X >= k)\\nprint(f\"P-value: {p_value:.4f}\")'}]}, {'id': 'exercise', 'title': 'Your turn: interpret a p-value', 'minutes': 5, 'blocks': [{'type': 'text', 'content': 'Suppose you roll a six-sided die 60 times and get 15 sixes. If the die is fair, the expected number of sixes is 10. Use the p-value concept to decide if 15 sixes is surprising. What does a small or large p-value tell you in this situation?'}]}]}",
         "{\n  \"objective\": \"Explain what a p-value represents in hypothesis testing and interpret its meaning in context.\",\n  \"sections\": [\n    {\n      \"id\": \"concept\",\n      \"title\": \"Understanding the p-value\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"A p-value helps us decide if our data is surprising under a specific assumption called the null hypothesis. It tells us the probability of seeing data as extreme as ours if the null hypothesis is true. A small p-value means the observed data is unlikely under the null hypothesis, suggesting that we might question this assumption.\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example\",\n      \"title\": \"Worked example with coin flips\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Imagine you flip a coin 10 times to test if it is fair. You get 9 heads. The p-value tells us how likely it is to get 9 or more heads if the coin is fair (null hypothesis). We calculate this probability to see if getting 9 heads is surprising.\"\n        },\n        {\n          \"type\": \"python\",\n          \"content\": \"from scipy.stats import binom\\n\\n# Number of flips\\nn = 10\\n# Number of observed heads\\nk = 9\\n# Probability of heads under null hypothesis\\np = 0.5\\n\\n# Calculate p-value: probability of 9 or more heads if coin is fair\\np_value = binom.sf(k-1, n, p)  # sf(k-1) = P(X >= k)\\nprint(f\\\"P-value: {p_value:.4f}\\\")\"\n        }\n      ]\n    },\n    {\n      \"id\": \"exercise\",\n      \"title\": \"Your turn: interpret a p-value\",\n      \"minutes\": 5,\n      \"blocks\": [\n        {\n          \"type\": \"text\",\n          \"content\": \"Suppose you roll a six-sided die 60 times and get 15 sixes. If the die is fair, the expected number of sixes is 10. Use the p-value concept to decide if 15 sixes is surprising. What does a small or large p-value tell you in this situation?\"\n        }\n      ]\n    }\n  ]\n}"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>topic</th>\n",
       "      <th>level</th>\n",
       "      <th>valid_json</th>\n",
       "      <th>lesson_data</th>\n",
       "      <th>raw_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming_beginner</td>\n",
       "      <td>pandas groupby performance</td>\n",
       "      <td>beginner</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Understand how to use pandas gr...</td>\n",
       "      <td>{\\n  \"objective\": \"Understand how to use panda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programming_intermediate</td>\n",
       "      <td>optimize pandas groupby memory usage</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Learn to reduce memory usage wh...</td>\n",
       "      <td>{\\n  \"objective\": \"Learn to reduce memory usag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_concept_beginner</td>\n",
       "      <td>correlation vs causation</td>\n",
       "      <td>beginner</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Explain the difference between ...</td>\n",
       "      <td>{\\n  \"objective\": \"Explain the difference betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_concept_intermediate</td>\n",
       "      <td>bias vs variance trade-off</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Explain the bias-variance trade...</td>\n",
       "      <td>{\\n  \"objective\": \"Explain the bias-variance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analytics_reasoning_beginner</td>\n",
       "      <td>interpreting A/B test results</td>\n",
       "      <td>beginner</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Explain how to interpret the re...</td>\n",
       "      <td>{\\n  \"objective\": \"Explain how to interpret th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>analytics_reasoning_intermediate</td>\n",
       "      <td>common pitfalls in KPI interpretation</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Identify and avoid common pitfa...</td>\n",
       "      <td>{\\n  \"objective\": \"Identify and avoid common p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>statistics_intuition_beginner</td>\n",
       "      <td>what a p-value means</td>\n",
       "      <td>beginner</td>\n",
       "      <td>True</td>\n",
       "      <td>{'objective': 'Explain what a p-value represen...</td>\n",
       "      <td>{\\n  \"objective\": \"Explain what a p-value repr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               case                                  topic  \\\n",
       "0              programming_beginner             pandas groupby performance   \n",
       "1          programming_intermediate   optimize pandas groupby memory usage   \n",
       "2             data_concept_beginner               correlation vs causation   \n",
       "3         data_concept_intermediate             bias vs variance trade-off   \n",
       "4      analytics_reasoning_beginner          interpreting A/B test results   \n",
       "5  analytics_reasoning_intermediate  common pitfalls in KPI interpretation   \n",
       "6     statistics_intuition_beginner                   what a p-value means   \n",
       "\n",
       "          level  valid_json  \\\n",
       "0      beginner        True   \n",
       "1  intermediate        True   \n",
       "2      beginner        True   \n",
       "3  intermediate        True   \n",
       "4      beginner        True   \n",
       "5  intermediate        True   \n",
       "6      beginner        True   \n",
       "\n",
       "                                         lesson_data  \\\n",
       "0  {'objective': 'Understand how to use pandas gr...   \n",
       "1  {'objective': 'Learn to reduce memory usage wh...   \n",
       "2  {'objective': 'Explain the difference between ...   \n",
       "3  {'objective': 'Explain the bias-variance trade...   \n",
       "4  {'objective': 'Explain how to interpret the re...   \n",
       "5  {'objective': 'Identify and avoid common pitfa...   \n",
       "6  {'objective': 'Explain what a p-value represen...   \n",
       "\n",
       "                                          raw_output  \n",
       "0  {\\n  \"objective\": \"Understand how to use panda...  \n",
       "1  {\\n  \"objective\": \"Learn to reduce memory usag...  \n",
       "2  {\\n  \"objective\": \"Explain the difference betw...  \n",
       "3  {\\n  \"objective\": \"Explain the bias-variance t...  \n",
       "4  {\\n  \"objective\": \"Explain how to interpret th...  \n",
       "5  {\\n  \"objective\": \"Identify and avoid common p...  \n",
       "6  {\\n  \"objective\": \"Explain what a p-value repr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c53c1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to a csv file in the data folder\n",
    "results_df.to_csv(\"data/lesson_generation_test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7f543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
